{
  "subreddit": "ollama",
  "url": "https://www.reddit.com/r/ollama",
  "meta": {
    "title": "ollama"
  },
  "posts": [
    {
      "title": "What does the \"updated\" date actually mean?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n6ply3/what_does_the_updated_date_actually_mean/",
      "score": 3,
      "comments": 5,
      "post_id": "t3_1n6ply3",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "XdtTransform",
      "author_id": "t2_298xrpy1",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-09-02T17:20:32.628000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n6ply3/what_does_the_updated_date_actually_mean/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "I trapped an LLM into a Raspberry Pi and it spiraled into an existential crisis",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n50fbq/i_trapped_an_llm_into_a_raspberry_pi_and_it/",
      "score": 241,
      "comments": 37,
      "post_id": "t3_1n50fbq",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "jbassi",
      "author_id": "t2_6o6qb",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T17:19:34.760000+0000",
      "content_href": "https://i.redd.it/tbq738w72emf1.png",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "Bringing Computer Use to the Web",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n57pbc/bringing_computer_use_to_the_web/",
      "score": 16,
      "comments": 0,
      "post_id": "t3_1n57pbc",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T22:14:20.665000+0000",
      "content_href": "https://v.redd.it/xk2qkemyifmf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/bringing-computer-use-to-the-web-v0-ODYzMWt4Y3lpZm1mMRcxEnlpDBBJVNjXlCDC4HUtgXjfB5ufLszRpp9PEi0H.png?width=640&crop=smart&format=pjpg&auto=webp&s=05fe7d89d2d5947775b9fc60b36508771b08dd5f"
    },
    {
      "title": "I made a no-install-needed web-GUI for Ollama",
      "permalink": "https://www.reddit.com/r/ollama/comments/1ms8ghv/i_made_a_noinstallneeded_webgui_for_ollama/",
      "score": 368,
      "comments": 38,
      "post_id": "t3_1ms8ghv",
      "post_type": "gallery",
      "domain": "reddit.com",
      "author": "DarkTom21",
      "author_id": "t2_1j8q1c9z",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-16T21:32:51.404000+0000",
      "content_href": "https://www.reddit.com/gallery/1ms8ghv",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_k6zix/styles/profileIcon_jm4dc62jjx6b1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=c8e7106bc607f44c99eb882b74b124772e20eb90"
    },
    {
      "title": "gpt-oss:20b on Ollama, Q5_K_M and llama.cpp vulkan benchmarks",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n4wlzb/gptoss20b_on_ollama_q5_k_m_and_llamacpp_vulkan/",
      "score": 19,
      "comments": 3,
      "post_id": "t3_1n4wlzb",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "tabletuser_blogspot",
      "author_id": "t2_h52tr",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T14:47:10.748000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n4wlzb/gptoss20b_on_ollama_q5_k_m_and_llamacpp_vulkan/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_clglu/styles/profileIcon_s1c0hncruyz41.jpg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=b813f5574951c6442501c04956a1d245c00501e0"
    },
    {
      "title": "Just released version 1.4 of Nanocoder built in Ink - such an epic framework for CLI applications!",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n1v1uw/just_released_version_14_of_nanocoder_built_in/",
      "score": 150,
      "comments": 22,
      "post_id": "t3_1n1v1uw",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "willlamerton",
      "author_id": "t2_cj4fewg1",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-27T22:21:00.634000+0000",
      "content_href": "https://i.redd.it/vkqp6dgi0nlf1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/just-released-version-1-4-of-nanocoder-built-in-ink-such-an-v0-vkqp6dgi0nlf1.jpeg?width=640&crop=smart&auto=webp&s=c8092645c19c60f6d888500bc2971f30ef3dbaf6"
    },
    {
      "title": "can Ollama run image generation models like Qwen -Image ?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n4nf4w/can_ollama_run_image_generation_models_like_qwen/",
      "score": 11,
      "comments": 12,
      "post_id": "t3_1n4nf4w",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "abrandis",
      "author_id": "t2_wgxvw",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T06:19:13.415000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n4nf4w/can_ollama_run_image_generation_models_like_qwen/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Trying to understand why ollama uses my GPU when run in a container but not when run bare metal.",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n6paet/trying_to_understand_why_ollama_uses_my_gpu_when/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1n6paet",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "79215185-1feb-44c6",
      "author_id": "t2_dx8q7riq",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-09-02T17:08:27.055000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n6paet/trying_to_understand_why_ollama_uses_my_gpu_when/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_4wi5t2/styles/profileIcon_3vtyidcozyhf1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=1a4594d6bc2faeaba9b399724d87c78974dc4bdf"
    },
    {
      "title": "I ran OpenAI’s GPT-OSS 20B locally on a 16GB Mac with Ollama — setup, gotchas, and mini demo",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mm4ibk/i_ran_openais_gptoss_20b_locally_on_a_16gb_mac/",
      "score": 325,
      "comments": 48,
      "post_id": "t3_1mm4ibk",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Spirited-Wind6803",
      "author_id": "t2_i4ktj1qy",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-10T00:19:29.793000+0000",
      "content_href": "https://v.redd.it/qlifjvit43if1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/i-ran-openais-gpt-oss-20b-locally-on-a-16gb-mac-with-ollama-v0-MHQ5M3V2aXQ0M2lmMf_ZwYHO2m1fMNCQy9M-9mV9J_Z510ikdbK6GDGwXk75.png?width=640&crop=smart&format=pjpg&auto=webp&s=68f48785ebadc0f2198e13a6b1df68de87e1496e"
    },
    {
      "title": "Using a model from ollama to take extracted PDF text and turn it into a CSV?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n4gnze/using_a_model_from_ollama_to_take_extracted_pdf/",
      "score": 5,
      "comments": 4,
      "post_id": "t3_1n4gnze",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "FudgeOk4045",
      "author_id": "t2_bkjpri7g",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T00:13:28.441000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n4gnze/using_a_model_from_ollama_to_take_extracted_pdf/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "Ollama + PostgreSQL: Your Local LLM Can Now Query Production Databases",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n1tfj4/ollama_postgresql_your_local_llm_can_now_query/",
      "score": 126,
      "comments": 10,
      "post_id": "t3_1n1tfj4",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Sea-Assignment6371",
      "author_id": "t2_sgy5sedla",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-27T21:17:07.569000+0000",
      "content_href": "https://v.redd.it/9qyoordvomlf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/ollama-postgresql-your-local-llm-can-now-query-production-v0-d2huZzF2ZHZvbWxmMblmm4Un8wPzClWvKIqbCd-O0tnIDr4HTaJ8aTVXM2nL.png?width=640&crop=smart&format=pjpg&auto=webp&s=528048be5759b33c8e36af8735dd8fe775de7973"
    },
    {
      "title": "Cua is hiring a Founding Engineer, UX & Design in SF",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n489hq/cua_is_hiring_a_founding_engineer_ux_design_in_sf/",
      "score": 9,
      "comments": 4,
      "post_id": "t3_1n489hq",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-30T18:04:09.728000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n489hq/cua_is_hiring_a_founding_engineer_ux_design_in_sf/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "First known AI-powered ransomware. Ollama API + gpt-oss-20b",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n4t8bm/first_known_aipowered_ransomware_ollama_api/",
      "score": 93,
      "comments": 11,
      "post_id": "t3_1n4t8bm",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "Cryptodude2000",
      "author_id": "t2_2j4emfep",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-31T12:19:05.125000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n4t8bm/first_known_aipowered_ransomware_ollama_api/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Can you use amd 9000 gpus",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n3zi12/can_you_use_amd_9000_gpus/",
      "score": 6,
      "comments": 6,
      "post_id": "t3_1n3zi12",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "kabyking",
      "author_id": "t2_46y55zds",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-30T11:42:39.861000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n3zi12/can_you_use_amd_9000_gpus/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Ollama’s copy-paste dev strategy is just PR spin?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mnirls/ollamas_copypaste_dev_strategy_is_just_pr_spin/",
      "score": 311,
      "comments": 29,
      "post_id": "t3_1mnirls",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "bllshrfv",
      "author_id": "t2_39i1zb05",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-11T17:07:02.550000+0000",
      "content_href": "https://i.redd.it/g9y4dwqw9fif1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/ollamas-copy-paste-dev-strategy-is-just-pr-spin-v0-g9y4dwqw9fif1.jpeg?width=640&crop=smart&auto=webp&s=ec489a758179f8a2451dba7f3526a8dc706dca1b"
    },
    {
      "title": "Computer Use on Windows Sandbox",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n46j3c/computer_use_on_windows_sandbox/",
      "score": 84,
      "comments": 1,
      "post_id": "t3_1n46j3c",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-30T16:52:47.068000+0000",
      "content_href": "https://v.redd.it/c0rqqugns6mf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/computer-use-on-windows-sandbox-v0-bGxuZjA0N25zNm1mMUUIhfD3WmHuxYkgbFXnt7PvLDhATd-8_6cYVR-PGp7c.png?width=640&crop=smart&format=pjpg&auto=webp&s=17353d1fbc3fd66d5975050832b88e31ec97fa9c"
    },
    {
      "title": "How to disable thinking mode for qwen3 in Ollama desktup UI?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n3yxzu/how_to_disable_thinking_mode_for_qwen3_in_ollama/",
      "score": 3,
      "comments": 5,
      "post_id": "t3_1n3yxzu",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "mohnos",
      "author_id": "t2_3af6o",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-30T11:11:05.034000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n3yxzu/how_to_disable_thinking_mode_for_qwen3_in_ollama/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Which model to choose for content generation?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n302ll/which_model_to_choose_for_content_generation/",
      "score": 5,
      "comments": 5,
      "post_id": "t3_1n302ll",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "fullstackdev-channel",
      "author_id": "t2_vhlh9iwx",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-29T06:35:41.431000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n302ll/which_model_to_choose_for_content_generation/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "I’ve Debugged 100+ RAG/LLM Pipelines. These 16 Bugs Always Come Back. (70 days, 800 stars)",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n2c5mw/ive_debugged_100_ragllm_pipelines_these_16_bugs/",
      "score": 61,
      "comments": 7,
      "post_id": "t3_1n2c5mw",
      "post_type": "link",
      "domain": "github.com",
      "author": "onestardao",
      "author_id": "t2_v4t0lnqrl",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-28T13:25:01.047000+0000",
      "content_href": "https://github.com/onestardao/WFGY/tree/main/ProblemMap/README.md",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "LLM Radio Theater, open source, 2 LLMs use Ollama and Chatterbox to have an unscripted conversation initiated by a start-prompt.",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n03afe/llm_radio_theater_open_source_2_llms_use_ollama/",
      "score": 17,
      "comments": 3,
      "post_id": "t3_1n03afe",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "JELSTUDIO",
      "author_id": "t2_3pie5ck3",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-25T21:29:12.803000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n03afe/llm_radio_theater_open_source_2_llms_use_ollama/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "Multiple personality Gemma 3",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n02kkv/multiple_personality_gemma_3/",
      "score": 9,
      "comments": 4,
      "post_id": "t3_1n02kkv",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "OkTransportation568",
      "author_id": "t2_hewgnvuz",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-25T21:01:54.400000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n02kkv/multiple_personality_gemma_3/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Ollamacode - Local AI assistant that can create, run and understand the task at hand!",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mfqqxp/ollamacode_local_ai_assistant_that_can_create_run/",
      "score": 304,
      "comments": 16,
      "post_id": "t3_1mfqqxp",
      "post_type": "gif",
      "domain": "i.redd.it",
      "author": "Loud-Consideration-2",
      "author_id": "t2_2lznz5yi",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-02T13:37:23.010000+0000",
      "content_href": "https://i.redd.it/yr8fwz5ezlgf1.gif",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/ollamacode-local-ai-assistant-that-can-create-run-and-v0-yr8fwz5ezlgf1.gif?width=640&crop=smart&format=png8&s=5747f87a356eb1286b185de7f7c7d49a59f94618"
    },
    {
      "title": "DataKit + Ollama = Your Data, Your AI, Your Way!",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mp00lq/datakit_ollama_your_data_your_ai_your_way/",
      "score": 258,
      "comments": 40,
      "post_id": "t3_1mp00lq",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Sea-Assignment6371",
      "author_id": "t2_sgy5sedla",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-13T09:45:29.678000+0000",
      "content_href": "https://v.redd.it/whi92hodcrif1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/datakit-ollama-your-data-your-ai-your-way-v0-MHVraTFpb2RjcmlmMau2qwmbGQWxbzW-5uoWUCNNcejArm0w5kuQ7jVz7rlm.png?width=640&crop=smart&format=pjpg&auto=webp&s=7d660c95e9c375cc36653dabe300c03dbb0d83bd"
    },
    {
      "title": "This is just a test but works",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n0fuf4/this_is_just_a_test_but_works/",
      "score": 44,
      "comments": 3,
      "post_id": "t3_1n0fuf4",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "bercha9998",
      "author_id": "t2_a2bhyp0g",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-26T08:00:18.477000+0000",
      "content_href": "https://i.redd.it/k714lga1mblf1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/this-is-just-a-test-but-works-v0-k714lga1mblf1.jpeg?width=640&crop=smart&auto=webp&s=5ae2afd05408ec27e286a57315178e4b8b460dbe"
    },
    {
      "title": "Computer-Use Agents SOTA Challenge @ Hack the North (YC interview for top team) + Global Online ($2000 prize)",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mzuy5y/computeruse_agents_sota_challenge_hack_the_north/",
      "score": 9,
      "comments": 1,
      "post_id": "t3_1mzuy5y",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-25T16:17:41.751000+0000",
      "content_href": "https://i.redd.it/52u8vi3vx6lf1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/computer-use-agents-sota-challenge-hack-the-north-yc-v0-52u8vi3vx6lf1.jpeg?width=640&crop=smart&auto=webp&s=06fadd5fd2c529e42aa8216ccc2d566635e18960"
    },
    {
      "title": "Local model for coding",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n0ht8x/local_model_for_coding/",
      "score": 39,
      "comments": 12,
      "post_id": "t3_1n0ht8x",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "vital101",
      "author_id": "t2_15vxc",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-26T10:08:27.653000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n0ht8x/local_model_for_coding/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "gpt-oss now available on Ollama",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mig251/gptoss_now_available_on_ollama/",
      "score": 257,
      "comments": 42,
      "post_id": "t3_1mig251",
      "post_type": "link",
      "domain": "ollama.com",
      "author": "john_rage",
      "author_id": "t2_5dke4",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-05T17:48:20.514000+0000",
      "content_href": "https://ollama.com/library/gpt-oss",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_crv52/styles/profileIcon_v3tpjfh1mt3d1.jpg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=8880bc97d5c9f86b057e72cb75557bfd27f8ca54"
    },
    {
      "title": "Is this the best value machine to run Local LLMs?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mh9jac/is_this_the_best_value_machine_to_run_local_llms/",
      "score": 240,
      "comments": 152,
      "post_id": "t3_1mh9jac",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "optimism0007",
      "author_id": "t2_14td4mcfn0",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-04T10:14:19.765000+0000",
      "content_href": "https://i.redd.it/4m8omr1w9zgf1.png",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "Making an RAG embedding Redis with Ollama",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mzsdh9/making_an_rag_embedding_redis_with_ollama/",
      "score": 8,
      "comments": 0,
      "post_id": "t3_1mzsdh9",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "jasonhon2013",
      "author_id": "t2_481uatyy",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-25T14:43:13.089000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mzsdh9/making_an_rag_embedding_redis_with_ollama/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_23tjp1/styles/profileIcon_54gqtz879v5f1.jpeg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=263d000942cc9a5f6d4fde3ae49f280ad1444a41"
    },
    {
      "title": "Pair a vision grounding model with a reasoning LLM with Cua",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n1m9fk/pair_a_vision_grounding_model_with_a_reasoning/",
      "score": 34,
      "comments": 3,
      "post_id": "t3_1n1m9fk",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-27T16:46:06.256000+0000",
      "content_href": "https://v.redd.it/7io8lg1rcllf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/pair-a-vision-grounding-model-with-a-reasoning-llm-with-cua-v0-dzUycDIzdHFjbGxmMbzuqtV-zsPSC2s-Lu_18m-UGy8cX2XwaXvrFiOhDTxh.png?width=640&crop=smart&format=pjpg&auto=webp&s=9d0108f55003bb9ce2d053ca013578f169d8d287"
    },
    {
      "title": "Human in the Loop for computer use agents",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n3bafx/human_in_the_loop_for_computer_use_agents/",
      "score": 32,
      "comments": 1,
      "post_id": "t3_1n3bafx",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-29T15:57:53.530000+0000",
      "content_href": "https://v.redd.it/zi8focpydzlf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/human-in-the-loop-for-computer-use-agents-v0-ZGY1MTQ4aHlkemxmMUvZR3OLyxwRXjlbiYrrBtxMf6dd5k6Y_Z_HAekaHP-j.png?width=640&crop=smart&format=pjpg&auto=webp&s=3ef40ec2411ee57573d4e8c806c784495aaf0678"
    },
    {
      "title": "ollama + webui + iis reverse proxy",
      "permalink": "https://www.reddit.com/r/ollama/comments/1myj3bs/ollama_webui_iis_reverse_proxy/",
      "score": 5,
      "comments": 6,
      "post_id": "t3_1myj3bs",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "dangit541",
      "author_id": "t2_6hkc9hz0",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-24T01:40:43.751000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1myj3bs/ollama_webui_iis_reverse_proxy/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Model recommendation for homelab use",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mygicl/model_recommendation_for_homelab_use/",
      "score": 6,
      "comments": 3,
      "post_id": "t3_1mygicl",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "Zageyiff",
      "author_id": "t2_2uzcaosa",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T23:33:59.449000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mygicl/model_recommendation_for_homelab_use/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Anyone know if Ollama will implement support for --cpu-moe ?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mycbtn/anyone_know_if_ollama_will_implement_support_for/",
      "score": 6,
      "comments": 0,
      "post_id": "t3_1mycbtn",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "The_Councillor",
      "author_id": "t2_4idim",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T20:36:50.761000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mycbtn/anyone_know_if_ollama_will_implement_support_for/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Ollama removed the link to GitHub",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mijg4m/ollama_removed_the_link_to_github/",
      "score": 240,
      "comments": 45,
      "post_id": "t3_1mijg4m",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "waescher",
      "author_id": "t2_1gpif4cz",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-05T19:52:42.025000+0000",
      "content_href": "https://i.redd.it/bk6utn9v99hf1.png",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/ollama-removed-the-link-to-github-v0-bk6utn9v99hf1.png?width=640&crop=smart&auto=webp&s=e6f09a8adf284322471188e65e5dff0fcd791990"
    },
    {
      "title": "GPT 5 for Computer Use agents.",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mklwrl/gpt_5_for_computer_use_agents/",
      "score": 203,
      "comments": 37,
      "post_id": "t3_1mklwrl",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Impressive_Half_2819",
      "author_id": "t2_1fpbfjtnc5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-08T04:37:34.490000+0000",
      "content_href": "https://v.redd.it/wxbv78dg5qhf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://external-preview.redd.it/gpt-5-for-computer-use-agents-v0-amZianVtMGc1cWhmMffa9LUhs6wvp7jU6XPjtPFZB1S0k_8zNod6eLcZn2nM.png?width=640&crop=smart&format=pjpg&auto=webp&s=a961d93f52e4e23b03da4a622558b7e79664e8af"
    },
    {
      "title": "Is there a Ollama GUI app for Linux like there is for macOS and Windows?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1my91m1/is_there_a_ollama_gui_app_for_linux_like_there_is/",
      "score": 6,
      "comments": 9,
      "post_id": "t3_1my91m1",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "gianndev_",
      "author_id": "t2_1mruz2pqmg",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T18:26:45.167000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1my91m1/is_there_a_ollama_gui_app_for_linux_like_there_is/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "I just had my first contributor to my open source AI coding agent and it feels great!",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mpi9rq/i_just_had_my_first_contributor_to_my_open_source/",
      "score": 201,
      "comments": 27,
      "post_id": "t3_1mpi9rq",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "willlamerton",
      "author_id": "t2_cj4fewg1",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-13T22:08:51.392000+0000",
      "content_href": "https://i.redd.it/xat5ofgh1vif1.png",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/i-just-had-my-first-contributor-to-my-open-source-ai-coding-v0-xat5ofgh1vif1.png?width=640&crop=smart&auto=webp&s=37f9953ca09e090928efd12e3278874fb6f04038"
    },
    {
      "title": "What is wrong in this conf",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n5lrmj/what_is_wrong_in_this_conf/",
      "score": 0,
      "comments": 3,
      "post_id": "t3_1n5lrmj",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "Rich_Artist_8327",
      "author_id": "t2_1jk2ep8a52",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-09-01T11:04:59.214000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n5lrmj/what_is_wrong_in_this_conf/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Best models under 16GB",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mjo9ki/best_models_under_16gb/",
      "score": 168,
      "comments": 51,
      "post_id": "t3_1mjo9ki",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "Mr-Barack-Obama",
      "author_id": "t2_igdar",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-07T02:31:33.412000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mjo9ki/best_models_under_16gb/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "AMD 395 128GB ram VS Apple Mac Air 10-core 32GB ram",
      "permalink": "https://www.reddit.com/r/ollama/comments/1my3k3t/amd_395_128gb_ram_vs_apple_mac_air_10core_32gb_ram/",
      "score": 10,
      "comments": 8,
      "post_id": "t3_1my3k3t",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "quantrpeter",
      "author_id": "t2_354zxl3r",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T14:54:54.271000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1my3k3t/amd_395_128gb_ram_vs_apple_mac_air_10core_32gb_ram/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_vw0np/styles/profileIcon_2tvkf029nbe21.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=0ebf0385386a8e77b377271cd348836a88e7293f"
    },
    {
      "title": "GPT-OSS Web Search",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n18h8q/gptoss_web_search/",
      "score": 30,
      "comments": 15,
      "post_id": "t3_1n18h8q",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "No-Engineering3583",
      "author_id": "t2_s8svz6ya",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-27T05:19:42.707000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n18h8q/gptoss_web_search/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Which LLM model is best for extracting exact or ranged dates from natural language queries?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n5jl9m/which_llm_model_is_best_for_extracting_exact_or/",
      "score": 0,
      "comments": 1,
      "post_id": "t3_1n5jl9m",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "ExpertDeal9883",
      "author_id": "t2_7b0wuyz5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-09-01T08:52:31.972000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n5jl9m/which_llm_model_is_best_for_extracting_exact_or/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "ThinkPad for Local LLM Inference - Linux Compatibility Questions",
      "permalink": "https://www.reddit.com/r/ollama/comments/1my7010/thinkpad_for_local_llm_inference_linux/",
      "score": 3,
      "comments": 6,
      "post_id": "t3_1my7010",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "1guyonearth",
      "author_id": "t2_vfjicjya5",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T17:09:02.983000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1my7010/thinkpad_for_local_llm_inference_linux/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "PSA: Secure Your Ollama / LLM Ports ( Even on Home LAN )",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mn653l/psa_secure_your_ollama_llm_ports_even_on_home_lan/",
      "score": 161,
      "comments": 30,
      "post_id": "t3_1mn653l",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "Immediate_Fun4182",
      "author_id": "t2_cyuljqfj4",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-11T07:02:47.097000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mn653l/psa_secure_your_ollama_llm_ports_even_on_home_lan/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Mac Mini M4 32GB vs limited PC upgrade for local AI - tight budget",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mxtpuz/mac_mini_m4_32gb_vs_limited_pc_upgrade_for_local/",
      "score": 19,
      "comments": 31,
      "post_id": "t3_1mxtpuz",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "Street_Trek_7754",
      "author_id": "t2_178vtvifyj",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T06:08:18.908000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mxtpuz/mac_mini_m4_32gb_vs_limited_pc_upgrade_for_local/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Qwen 4B on iPhone Neural Engine runs at 20t/s",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mslsvy/qwen_4b_on_iphone_neural_engine_runs_at_20ts/",
      "score": 145,
      "comments": 58,
      "post_id": "t3_1mslsvy",
      "post_type": "video",
      "domain": "v.redd.it",
      "author": "Glad-Speaker3006",
      "author_id": "t2_w5xu1ep7l",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-17T08:46:29.193000+0000",
      "content_href": "https://v.redd.it/xewf9vn2mjjf1",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "ollama-lancache (like caching games for a lan party but models instead!)",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n2pspb/ollamalancache_like_caching_games_for_a_lan_party/",
      "score": 26,
      "comments": 6,
      "post_id": "t3_1n2pspb",
      "post_type": "multi_media",
      "domain": "self.ollama",
      "author": "jjasghar",
      "author_id": "t2_5n8i2",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-28T22:07:13.585000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n2pspb/ollamalancache_like_caching_games_for_a_lan_party/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "What model should I use?",
      "permalink": "https://www.reddit.com/r/ollama/comments/1n5gp7s/what_model_should_i_use/",
      "score": 3,
      "comments": 6,
      "post_id": "t3_1n5gp7s",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "Ok_Examination_7236",
      "author_id": "t2_1a929i71a8",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-09-01T05:51:37.655000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1n5gp7s/what_model_should_i_use/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Best model for my use case (updated)",
      "permalink": "https://www.reddit.com/r/ollama/comments/1mxqthv/best_model_for_my_use_case_updated/",
      "score": 6,
      "comments": 4,
      "post_id": "t3_1mxqthv",
      "post_type": "text",
      "domain": "self.ollama",
      "author": "guacgang",
      "author_id": "t2_3xakjt3y",
      "subreddit_id": "t5_8sk7f8",
      "subreddit": "r/ollama",
      "created_ts": "2025-08-23T03:26:32.815000+0000",
      "content_href": "https://www.reddit.com/r/ollama/comments/1mxqthv/best_model_for_my_use_case_updated/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    }
  ],
  "scraped_at": "2025-09-02T11:37:38.532425"
}