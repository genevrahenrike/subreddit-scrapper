{
  "subreddit": "rstats",
  "url": "https://www.reddit.com/r/rstats",
  "meta": {
    "title": "The Statistical Computing with R subreddit"
  },
  "posts": [
    {
      "title": "Colour Prediction Website Need A Partner",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n6pfl6/colour_prediction_website_need_a_partner/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1n6pfl6",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "MominulIslam12",
      "author_id": "t2_l7ebl7a7",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-09-02T17:13:55.531000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n6pfl6/colour_prediction_website_need_a_partner/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_7.png"
    },
    {
      "title": "25 Things You Didnâ€™t Know You Could Do with R (CascadiaRConf2025)",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n1tspt/25_things_you_didnt_know_you_could_do_with_r/",
      "score": 79,
      "comments": 6,
      "post_id": "t3_1n1tspt",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "mulderc",
      "author_id": "t2_5ral9",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-27T21:31:05.619000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n1tspt/25_things_you_didnt_know_you_could_do_with_r/",
      "content_preview": "I used to think R was pretty much just for stats and data analysis, but David Keyes' keynote at Cascadia R this year totally changed my perspective. He walked through 25 different things you can do with R that go way beyond your typical regression models and ggplot charts with some creative, some practical, and honestly some that caught me completely off guard. Definitely worth watching if you're stuck in a rut with your usual R workflow or just want some fresh inspiration for projects. ðŸŽ¥ Video here: https://youtu.be/wrPrIRcOVr0",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_5.png"
    },
    {
      "title": "Turning Support Chaos into Actionable Insights: A Data-Driven Approach to Customer Incident Management",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n47016/turning_support_chaos_into_actionable_insights_a/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1n47016",
      "post_type": "link",
      "domain": "medium.com",
      "author": "afaqbabar",
      "author_id": "t2_3jt6ign2",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-30T17:11:57.543000+0000",
      "content_href": "https://medium.com/@afaqbabar/turning-support-chaos-into-actionable-insights-a-data-driven-approach-to-customer-incident-59d0a251b435",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "Experience with Databricks as an R user?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mm1rxf/experience_with_databricks_as_an_r_user/",
      "score": 42,
      "comments": 23,
      "post_id": "t3_1mm1rxf",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "One-Plastic6501",
      "author_id": "t2_18rjx4farv",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-09T22:10:54.847000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mm1rxf/experience_with_databricks_as_an_r_user/",
      "content_preview": "Iâ€™m interested in R usersâ€™ opinions of Databricks. My work is really trying to push its use and I think theyâ€™ll eventually disallow running local R sessions entirely",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "Rstan takes forever to install ?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n391mu/rstan_takes_forever_to_install/",
      "score": 3,
      "comments": 9,
      "post_id": "t3_1n391mu",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "al3arabcoreleone",
      "author_id": "t2_1rcw8kbb",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-29T14:32:11.452000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n391mu/rstan_takes_forever_to_install/",
      "content_preview": "I am trying to install rstan but one of the required packages (RcppEigen) takes a lot of time that I force the installation to stop, is it normal or am I having problems in my computer ?",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_lomiw/styles/profileIcon_4tsgqd8ccjab1.jpeg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=8f3eea1718c790b53780818ff3d8ef5134219da3"
    },
    {
      "title": "Addicted to Pipes",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n108b4/addicted_to_pipes/",
      "score": 76,
      "comments": 40,
      "post_id": "t3_1n108b4",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-26T22:39:55.051000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n108b4/addicted_to_pipes/",
      "content_preview": "I can't help but use |> everywhere possible. Any similar experiences?",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "New trouble with creating variables that include a summary statistic",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n37swm/new_trouble_with_creating_variables_that_include/",
      "score": 0,
      "comments": 7,
      "post_id": "t3_1n37swm",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "ohbonobo",
      "author_id": "t2_5220v4ys",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-29T13:42:45.682000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n37swm/new_trouble_with_creating_variables_that_include/",
      "content_preview": "(SECOND EDIT WITH RESOLUTION) Turns out my original source dataframe was actually grouped rowwise for some reason, so the function was essentially trying to take the mean and standard deviation within each row, resulting in NA values for every row in the dataframe.  Now that I've removed the grouping, everything's working as expected. Thanks for the troubleshooting help! (EDITED BECAUSE ENTERED TOO SOON) I built a workflow for cleaning some data that included a couple of functions designed to standardize and reverse score variables.  Yesterday, when I was cleaning up my script to get it ready to share, I realized the functions were no longer working and were returning NAs for all cases.  I haven't been able to effectively figure out what's going wrong, but they have worked great in the past and I didn't change anything else that I know of. Ideas for troubleshooting what might have caused these functions to stop working and/or to fix them?  I tried troubleshooting with AI, but didn't get anything particularly helpful, so I figured humans might be the better avenue for help. For context, I'm working in RStudio (2025-05-01, Build 513) ## Example function: z_standardize <- function(x) {\n  var_mean <- mean(x, na.rm = TRUE)\n  std_dev <- sd(x, na.rm = TRUE)\n  return((x - var_mean) / std_dev)   # EDITED AS I WAS MISSING PARENTHESES\n  } ## Properties of a variable it is broken for: > str(df$wage)\n num [1:4650] 5.92 8 5.62 25 9.5 ...\n - attr(*, \"value.labels\")= Named num(0) \n  ..- attr(*, \"names\")= chr(0) \n\n> summary(wage)\n wage   \n Min.   :  1.286  \n 1st Qu.: 10.000  \n Median : 12.821  \n Mean   : 15.319  \n 3rd Qu.: 16.500  \n Max.   :107.500  \n NA's   :405 ## It's broken when I try this: df_test <- df %>% mutate(z_wage = z_standardize(wage)) > summary(df_test$z_wage)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA    4650 ## It works when I try this: > df_test$z_wage <- z_standardize(df_test$wage)    #EDITED DF NAME FOR CONSISTENCY\n> summary(df_test$z_wage)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -0.153   8.561  11.382  13.880  15.061 106.061     405 I couldn't get the error to replicate with this sample dataframe, ruining my idea that there was something about NA values that were breaking the function: df_sample <- tibble(a = c(1, 2, 4, 11), b = c(9, 18, 6, 1), c = c(3, 4, 5, NA))\n\ndf_sample_z <- df_sample %>% \n  mutate(z_a = z_standardize(a),\n         z_b = z_standardize(b),\n         z_c = z_standardize(c)) \n\n> df_sample_z\n# A tibble: 4 x 6\n      a     b     c    z_a     z_b   z_c\n  <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>\n1     1     9     3 -0.776  0.0700    -1\n2     2    18     4 -0.554  1.33       0\n3     4     6     5 -0.111 -0.350      1\n4    11     1    NA  1.44  -1.05      NA",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Colour Prediction Website Need Partnership",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n6peev/colour_prediction_website_need_partnership/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1n6peev",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "MominulIslam12",
      "author_id": "t2_l7ebl7a7",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-09-02T17:12:40.134000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n6peev/colour_prediction_website_need_partnership/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_7.png"
    },
    {
      "title": "uv for R",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mgdlsh/uv_for_r/",
      "score": 38,
      "comments": 51,
      "post_id": "t3_1mgdlsh",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Lanky-Introduction-9",
      "author_id": "t2_6ww6fpoz",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-03T07:54:03.285000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mgdlsh/uv_for_r/",
      "content_preview": "Someone really should build a similar tool for R as uv for Python. Conda does manage R versions and packages in a severely limited way. The whole Rstat users need a uv like tool asap.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "ggplot's geom_label() plotting in the wrong spot when adding \"fill = [color]\"",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n2x0qr/ggplots_geom_label_plotting_in_the_wrong_spot/",
      "score": 2,
      "comments": 2,
      "post_id": "t3_1n2x0qr",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "djn24",
      "author_id": "t2_krlqj",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-29T03:39:52.473000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n2x0qr/ggplots_geom_label_plotting_in_the_wrong_spot/",
      "content_preview": "https://preview.redd.it/ggplots-geom-label-plotting-in-the-wrong-spot-when-adding-v0-ufj7b3axpvlf1.png Hello, I'm working on putting together a grouped bar chart with labels above each bar. The code below is an example of what I'm working on. If I don't add a fill color to geom_label() , then the labels are plotted correctly with each bar. However, when I add the line fill = \"white\" to geom_label() , the labels revert back to the position they would be in with a stacked bar chart. The image in this post shows what I get when I add that white fill. Does anybody know a way to keep those labels positioned above each bar? Thank you! # Data\ndata <- data.frame(\n      category = rep(c(\"A\", \"B\", \"C\"), each = 2),\n      group = rep(c(\"X\", \"Y\"), 3),\n      value = c(10, 15, 8, 12, 14, 9)\n      )\n    \n# Create the grouped bar chart with white-filled labels\nggplot(data, aes(x = category, y = value, fill = group)) +\n      geom_bar(stat = \"identity\", position = position_dodge(width = 0.9)) +\n      geom_label(aes(label = value), \n                 position = position_dodge(width = 0.9), \n                 fill = \"white\") +\n      labs(title = \"Grouped Bar Chart with White Labels\",\n      x = \"Category\",\n      y = \"Value\") +\n      theme_minimal()",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Claude Code for R/RStudio with (almost) zero setup for Mac.",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n23pdw/claude_code_for_rrstudio_with_almost_zero_setup/",
      "score": 9,
      "comments": 14,
      "post_id": "t3_1n23pdw",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "AdSpecialist666",
      "author_id": "t2_9894mdvta",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-28T05:18:22.760000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n23pdw/claude_code_for_rrstudio_with_almost_zero_setup/",
      "content_preview": "Hi all, I'm quite fascinated by the Claude Code functionalities so I've implemented a : https://github.com/thomasxiaoxiao/rstudio-cc After installing the basics such as brew, npm, claude code, R..., you should then be able to interact with r/RStudio natively with CC, exposing the R execution logs so that CC has the visibility into the context. This should be quite helpful for debugging and more. Also, since I'm not really a heavy R user I'm also curious about the following from the community: what R/RStudio can provide that is still essential that prevent you from migrating to other languages and IDEs, such as Python +VScode? where the AI integrations are usually much better. Appreciate any feedback on the repo and discussions.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "I keep getting an Error and \"Object Not Found\"",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mzx47x/i_keep_getting_an_error_and_object_not_found/",
      "score": 0,
      "comments": 19,
      "post_id": "t3_1mzx47x",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "unceasingfish",
      "author_id": "t2_87krvp1e",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-25T17:36:56.369000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mzx47x/i_keep_getting_an_error_and_object_not_found/",
      "content_preview": "Hello all, I just started learning R last week and I have had a bit of a rocky start, but I am getting the hang of it (very slowly). Anyways, I am a scientist who needs help figuring out what's wrong with this code. I did not make this code, another scientist made it and gave it to me to experiment with. If information is needed, this is for an experiment fiddler crabs in quadrats and soil cores. (BTW Clusters are multiple crabs) I believe this code is supposed to lead up to the creation of an Excel file (an explanation of str() would be helpful as well). I have mixed and matched things that I think could be wrong with it, but it still goes to an error. Please let me know if it there isn't enough information, I really don't know why it isn't working. My errors include this: Error: object 'BlockswithClustersTop' not found\n\nError: object 'CrabsTop' not found\n\nError: object 'HowManyCrabs' not found Here is the current code: str(\"dataBlocks\")\nHowManyCrabs <- dataBlocks%>%\n  group_by(SurveyID)%>%\n  summarize(blocks=n(),\n            CrabsTopTotal = sum(CrabsTop),\n            CrabsBottomTotal = sum(CrabsBottom),\n            BlocksWithCrabsTop = sum(CrabsTop>0),\n            BlocksWithCrabsBottom = sum(CrabsBottom>0),\n            BlocksWithCrabs = sum(CrabsTop + CrabsBottom >0),\n            BlocksWithCrabsTop = sum(CrabsTop>0),\n            BlockswithClustersTop = sum(CrabsTop >1.5),\n            BlockswithClustersBottom = sum(CrabsBottom >1.5),\n            BlockswithClusters = sum(CrabsTop >1.5|CrabsBottom >1.5),\n            MinVegetationClass = as.factor(min(VegetationClass)),\n            MaxVegetationClass = as.factor(max(VegetationClass)),\n            AvgVegetationClass = as.factor(floor(mean(VegetationClass))),\n            MinHardness = min(Hardness,na.rm = TRUE),\n            MaxHardness = max(Hardness, na.rm = TRUE),\n            AvgHardness = mean(Hardness, na.rm = TRUE),\n            MinHardFloor = floor(MinHardness),\n            MaxHardFloor = floor(MaxHardness),\n            AvgHardFloor = floor(AvgHardness)) +\n  mutate(BlockswithClusters = BlockswithClustersTop + BlockswithClustersBottom,\n          Crabs = as.factor(ifelse(BlocksWithCrabs >0,\"YES\", \"NO\")),\n          Clusters = as.factor(ifelse(BlockswithClusters >0, \"YES\", \"NO\")),\n          TypeofCrabs = as.factor (ifelse(BlockswithClusters >0, \"CLUSTERS\",                 ifelse(BlocksWithCrabs >0,\"SINGLESONLY\",\"NOTHING\"))))\n\nstr(HowManyCrabs)\n\nwrite_csv(HowManyCrabs, \"HowManyCrabs.csv\")",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Built-In Skewness and Kurtosis Functions",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n5vp2m/builtin_skewness_and_kurtosis_functions/",
      "score": 6,
      "comments": 6,
      "post_id": "t3_1n5vp2m",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-09-01T17:54:12.363000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n5vp2m/builtin_skewness_and_kurtosis_functions/",
      "content_preview": "I often need to load the R package moments to use its skewness and kurtosis functions. Why they are not available in the fundamental R package stats?",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Uncertainty measures for net sentiment",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mzcwiy/uncertainty_measures_for_net_sentiment/",
      "score": 5,
      "comments": 5,
      "post_id": "t3_1mzcwiy",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Salty_Interest_7275",
      "author_id": "t2_8mt5n8och",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-25T00:58:56.730000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mzcwiy/uncertainty_measures_for_net_sentiment/",
      "content_preview": "Hi experts, I have aggregated survey results which I have transformed into net sentiment by taking the proportion disagree from the proportion agree. The groups vary in order of magnitude between 10 respondents up to 4000 respondents. How do I sensibly provide a measure of uncertainty so my audience gets a clear understanding of the variability associated with each score? Initial research suggested that parametric measures of uncertainty would not be appropriate given the groups can be so small. Over half of all responses come from groups that have less than 25 respondents. So the approach would need to be robust for small groups. Open to bayesian approaches. Thanks in advance!",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Lessons to Learn from Julia",
      "permalink": "https://www.reddit.com/r/rstats/comments/1ms1idt/lessons_to_learn_from_julia/",
      "score": 35,
      "comments": 39,
      "post_id": "t3_1ms1idt",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-16T17:18:12.343000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1ms1idt/lessons_to_learn_from_julia/",
      "content_preview": "When Julia was first introduced in 2012, it generated considerable excitement and attracted widespread interest within the data science and programming communities. Today, however, its relevance appears to be gradually waning. What lessons can R developers draw from Juliaâ€™s trajectory? I propose two key points: First, build on established foundations by deeply integrating with C and C++, rather than relying heavily on elaborate just-in-time (JIT) compilation strategies. Leveraging robust, time-tested technologies can enhance functionality and reliability without introducing unnecessary technical complications. Second, acknowledge and embrace Râ€™s role as a specialized programming language tailored for statistical computing and data analysis. Exercise caution when considering additions intended to make R more general-purpose; such complexities risk diluting its core strengths and compromising the simplicity that users value.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Display data on the axes - ggplot",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n6jar2/display_data_on_the_axes_ggplot/",
      "score": 1,
      "comments": 3,
      "post_id": "t3_1n6jar2",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "LaridaeLover",
      "author_id": "t2_1m0lhmz2om",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-09-02T13:20:59.024000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n6jar2/display_data_on_the_axes_ggplot/",
      "content_preview": "Hi all, I am having trouble coming up with an elegant solution to a problem Iâ€™m having. I have a simple plot using geom_line() to show growth curves with age on the x-axis and mass on the y-axis. I would like that the Y axis line be used to display a density curve of the average adult mass. So far, I have used geom_density with no fill and removed the Y axis line but it doesnâ€™t look too great. The density curve doesnâ€™t extend to 0, the x axis extends beyond 0 on the left, etc. Are there any resources that discuss how to do this?",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_ejotv9/styles/profileIcon_idaeaha7763f1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=d478271f59ec96039a24bdf9bd52d1a0fc0e184a"
    },
    {
      "title": "For anyone curious about the Positron IDE:  I found a neat guide on using it with Dev Containers",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mms925/for_anyone_curious_about_the_positron_ide_i_found/",
      "score": 35,
      "comments": 9,
      "post_id": "t3_1mms925",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "FriendlyAd5913",
      "author_id": "t2_74n4lzn2",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-10T19:51:57.676000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mms925/for_anyone_curious_about_the_positron_ide_i_found/",
      "content_preview": "Iâ€™ve been exploring Positron IDE lately and stumbled across a nice little guide that shows how to combine it with: Dev Containers for reproducible setups DevPod to run them anywhere Docker for local or remote execution Itâ€™s a simple, step-by-step walkthrough that makes it much easier to get Positron up and running in a portable dev environment. Repo & guide here: ðŸ‘‰ https://github.com/davidrsch/devcontainer_devpod_positron",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Sample size in Gpower: equal groups allocation?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mth696/sample_size_in_gpower_equal_groups_allocation/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1mth696",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Lorsleafs",
      "author_id": "t2_1rxxw3cirm",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-18T09:25:12.943000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mth696/sample_size_in_gpower_equal_groups_allocation/",
      "content_preview": "Hello everyone, I hope you are doing well. I have a (perhaps simple) question. Iâ€™m calculating an a priori sample size in G*Power for an F-test. My study is a 3 (Group; between) Ã— 3 (Phase/Measurement; within) Ã— 2 (Order of phase presentation; between) mixed design. I initially tried an R simulation, as I know that GPower is not very precise for mixed repeated-measures ANOVAs. However, my supervisors feel it is too complex and that we might be underpowered anyway, so, under the suggestion of our uni statistician, I am using a mixed ANOVA (repeated measures with a between-subjects factor) in GPower instead. We don't account for the within factor as he said it is implied in the repeated measure design. Iâ€™ve entered all the values (alpha, effect size, power) and specified 6 groups to reflect the Group Ã— Order cells. My question is: does the total sample size that G Power returns assume equal allocation of participants across the 6 groups, or not? From what I understand, in G Powerâ€™s repeated-measures ANOVA modules you cannot enter unequal cell sizes, so the reported total N should correspond to equal n per group. However, Iâ€™m not entirely sure. Does anyone know of an explicit source or documentation that confirms this? Thank you very much in advance â˜ºï¸",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "RStudio on macOS Tahoe",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mo432n/rstudio_on_macos_tahoe/",
      "score": 0,
      "comments": 7,
      "post_id": "t3_1mo432n",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "SarkyBot",
      "author_id": "t2_oq3fy",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-12T09:31:58.360000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mo432n/rstudio_on_macos_tahoe/",
      "content_preview": "Has anyone tried it and have you seen any issues? I don't recall many issues in new macOS versions in the past, but this is a major UI redesign and given RStudio's current wonky window behaviour I am wondering if this has got worse. (not expecting it to get better....)",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "Do rows not re-index? And I get a FALSE when I check that a condition matches, though I can see that specific item in my data frame",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mlutxm/do_rows_not_reindex_and_i_get_a_false_when_i/",
      "score": 0,
      "comments": 15,
      "post_id": "t3_1mlutxm",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "EngineEngine",
      "author_id": "t2_ihswp",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-09T17:17:28.225000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mlutxm/do_rows_not_reindex_and_i_get_a_false_when_i/",
      "content_preview": "I had a data frame with over three thousand rows. Then I filtered some data out, selected what I wanted, and built a new data frame. This new data frame has 738 rows. However, when I view the data frame, the rows are numbered with their original indices. It makes it confusing. For example, row 1 in the new data frame is row 4 from the original (see here ). Another issue. I'm trying to find the index of two specific rows that are the beginning and end of the time series. For the first, I do which(ts_data_cleaned$datetime == \"2024-07-24 18:00:00\") and I get row 471. I do the same for the end date: which(ts_data_cleaned$datetime == \"2024-09-06 15:00:05\") and the result is integer(0) . Then I tried any(ts_data_cleaned$datetime == \"2024-09-06 15:00:05\") and the result was FALSE . How is that possible when I can see it in the data frame? I've tried troubleshooting based on what I know and with AI, but can't crack it. TLDR: A created a new data frame from a subset of a larger one. When I view the data frame, the row numbers came from the original data frame, so row numbers go into the thousands, despite it having only 738 rows. I'm trying to get the row number for a datetime. Apparently my datetime doesn't exist, though I can see it in the data frame?",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Looking to learn R from practically scratch",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mvbk3j/looking_to_learn_r_from_practically_scratch/",
      "score": 34,
      "comments": 16,
      "post_id": "t3_1mvbk3j",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "18if",
      "author_id": "t2_q8vgomm",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-20T10:58:07.334000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mvbk3j/looking_to_learn_r_from_practically_scratch/",
      "content_preview": "like the title says I want to learn to code and graph in R for biology projects and have some experience with it but it was very much copy and paste and I am looking for courses or ideally free resources i can use to really sink my teeth and learn to use it on my own",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_a0ede/styles/profileIcon_15laaugxk12b1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=788308725ca7ca793d0c65edf73a6e11d83bceee"
    },
    {
      "title": "Copy the Pros: Recreate a NYTimes Chart in R",
      "permalink": "https://www.reddit.com/r/rstats/comments/1me1feq/copy_the_pros_recreate_a_nytimes_chart_in_r/",
      "score": 72,
      "comments": 7,
      "post_id": "t3_1me1feq",
      "post_type": "link",
      "domain": "youtu.be",
      "author": "Pecners",
      "author_id": "t2_35337pgu",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-31T13:21:55.963000+0000",
      "content_href": "https://youtu.be/XihJUrDXq6s",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Running AI-generated ggplot2: why we moved from WebR to cloud computing?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n4pblh/running_aigenerated_ggplot2_why_we_moved_from/",
      "score": 4,
      "comments": 1,
      "post_id": "t3_1n4pblh",
      "post_type": "link",
      "domain": "quesma.com",
      "author": "pmigdal",
      "author_id": "t2_u10sn",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-31T08:20:15.887000+0000",
      "content_href": "https://quesma.com/blog/sandboxing-ai-generated-code-why-we-moved-from-webr-to-aws-lambda/",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_e7jph/styles/profileIcon_yeoexxh48fp61.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=4dbd7aa0cbdc8cf699b73f4f30ff0c2cd4582c3c"
    },
    {
      "title": "Positron - .Rprofile not sourced when working in subdirectory of root",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n6bio5/positron_rprofile_not_sourced_when_working_in/",
      "score": 2,
      "comments": 10,
      "post_id": "t3_1n6bio5",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "HeartDistinct888",
      "author_id": "t2_1c9hqsmeqo",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-09-02T05:48:38.579000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n6bio5/positron_rprofile_not_sourced_when_working_in/",
      "content_preview": "Hi all, New user of Positron here, coming from RStudio. I have a codebase that looks like: > data_extraction\n  > extract_1.R\n  > extract_2.R\n> data_prep\n  > prep_1.R\n  > prep_2.R\n> modelling\n  > ...\n> my_codebase.Rproj\n>.Rprofile Each script requires that its immediate parent directory be the working directory when running the script. Maybe not best practise but I'm working with what I have. This is fairly easy to run in RStudio. I can run each script, and hit Set Working Directory when moving from one subdirectory to the next. After each script I can restart R to clear the global environment. Upon restarting R, I guess RStudio looks to the project root (as determined by the Rproj file) and finds/sources the .Rprofile. This is not the case in Positron. If my active directory is data_prep , then when restarting the R session, .Rprofile will not be sourced. This is an issue when working with renv , and leads to an annoying workflow requiring me to run setwd() far more often. Does anybody know a nice way around this? To get Positron to recognise a project root separate from the current active directory? The settings have a project option: terminal.integrated.cwd , which (re-)starts the terminal at the root directory only. This doesn't seem to apply to the R session, however. Options I've considered are: .Rprofile in every subdirectory - seems nasty Write a VSCode extension to do this - I don't really want to maintain something like this, and I'm not very good at JS. File Github issue, wait - I'll do this if nobody can help here Rewrite the code so all file paths are relative to the project root - lots of work across multiple codebases but probably a good idea",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "oRm: An object relational model framework for R",
      "permalink": "https://www.reddit.com/r/rstats/comments/1me3f44/orm_an_object_relational_model_framework_for_r/",
      "score": 32,
      "comments": 10,
      "post_id": "t3_1me3f44",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "binarypinkerton",
      "author_id": "t2_iqqtg",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-31T14:41:52.741000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1me3f44/orm_an_object_relational_model_framework_for_r/",
      "content_preview": "oRm is inspired by sqlalchemy. I kept wanting to reach for an ORM solution to provide a backend for things like interactive shiny tables or reproducible data entry. So, as they say \"be the change you want to see in the world.\" For those not previously introduced to ORM, it's an object oriented approach to CRUD operations via objects (rows) and their related data (foreign keys). You can think of oRm like a wrapper that takes your tried and true DBI connection methods and dbplyr filtering syntax to make R6 mutable objects. And once you have your objects, the real magic happens in the relationships. you can jump straight to the pkdown site here . A couple of points to get out of the way before I give an example: This package is not for analysis and statistical work, it's not for reading large tables (though it can), and it doesn't seek to improve on or compete with dbplyr, in fact I use dbplyr under the hood so I can rely on their dialect agnostic syntax as much as possible. Yes, reticulate does make sqlalchemy very easy to port into any R work. But what if you just don't know python very well, and / or don't want a .Renviron and a .env , and .renv/ and a .venv/ in your project? And a couple of features that I'm not going to get to in this post, but are likely to interest some people: with.Engine allows for a managed transaction state with automatic rollback in case of failure. on delete and on update support for related objects. Some dialect specific support, for example making use of a flush() method and RETURNING for postgres backends. Okay, now show me what it looks like Sure thing. oRm uses a few key objects: Engine: your db connection TableModel: a model representing a sql table Record: an object that represents a row in a table Relationships: mappings between TableModels that define how observations are linked together. The example below is based on the idea of having a data team entering measurements of plant heights during the course of an experiment. Engine The engine uses DBI under the hood. So the syntax should be very familiar, some might even say the exact same to what you're used to. This example uses SQLite, but you should be able to plop whatever driver you want in there. library(oRm)\n\nengine <- Engine$new(\n  drv = RSQLite::SQLite(),\n  dbname = \":memory:\",\n  persist = TRUE # this arg is sqlite memory specific, not always needed\n) Your engine will manage opening and closing connections for you. You can also implicitly create a managed pool with the argument use_pool=TRUE . There are a few methods that you might find useful from your engine itself, but for the most part you just define it and leave it be. TableModel You can use the TableModel$new() method, but I like the hierarchical structure of building my table model off the engine it relies on. Defining a TableModel you give a table name and a list of Columns. Measurements <- engine$model(\n  tablename = \"measurements\",\n  id = Column(\"INTEGER\", primary_key = TRUE),\n  observer_id = Column(\"INTEGER\"),\n  plant_id = ForeignKey(\"INTEGER\", references = 'plants.id'),\n  measurement_date = Column(\"DATE\"),\n  measurement_value = Column(\"REAL\")\n)\nMeasurements$create_table() Records Again, you can define a Record$new() but I like to make my records from the TableModel they came from. m1 = Measurements$record(\n  observer_id = 1,\n  plant_id = 101,\n  measurement_date = as.Date(\"2025-07-30\"),\n  measurement_value = 14.2\n)\n# and after we have m1, we need to explicitly create it in the db\nm1$create() At this point, we have our object representing a single row. If you go no further, this will give you CRUD functionality at the row level. The methods assigned to a Record are named to align with CRUD: m1$create()\nm1$update(measurement_value = 15)\n# m1$delete() The 'R' belongs to the table, since you're reading from there. Here's an example to get our m1 object from the table itself. You can use dbplyr filter syntax here. m1_read = Measurements$read(observer_id == 1, mode = 'get')\nm1_read If you've gotten this far, I'm going to consider you formally interested and refer you to the pkdown site for seeing the Relationships in action. This post mirrors that documenation, so you'll pick up right where you left off here.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "R vs Python",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mds0zi/r_vs_python/",
      "score": 61,
      "comments": 88,
      "post_id": "t3_1mds0zi",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Dillon_37",
      "author_id": "t2_vpouwviy",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-31T04:21:07.078000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mds0zi/r_vs_python/",
      "content_preview": "Is becoming a data scientist doable with only R proficiency (tidyverse,ggplot2, ML models, shiny...) and no python knowledge (Problems of a degree in probability and statistics)",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "Labelling a dendrogram",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n3bfaw/labelling_a_dendrogram/",
      "score": 0,
      "comments": 2,
      "post_id": "t3_1n3bfaw",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Bright_Flan4481",
      "author_id": "t2_1wmd63rr2k",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-29T16:02:47.622000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n3bfaw/labelling_a_dendrogram/",
      "content_preview": "I have a CSV file, the first few lines of which are: Distillery,Body,Sweetness,Smoky,Medicinal,Tobacco,Honey,Spicy,Winey,Nutty,Malty,Fruity,Floral Aberfeldy,2,2,2,0,0,3,2,2,1,2,2,2 Aberlour,3,3,1,0,0,3,2,2,3,3,3,2 Alt-A-Bhaine,1,3,1,0,0,1,2,0,1,2,2,2 I read this in using read.csv, setting header to TRUE. I then calculate a distance matrix, and perform hierarchical clustering. To plot the dendrogram I use: fviz_dend(hcr, cex = 0.5, horiz = TRUE, main = \"Dendrogram - ward.D2\") This gives me the dendrogram, but labelled with the line number in the file, rather than the distillery name. How do I make the dendrogram use the distillery name? Happy to provide the full CSV file if this helps.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "Creating an DF of events in one DF that happened within a certain range of another DF",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n3ague/creating_an_df_of_events_in_one_df_that_happened/",
      "score": 0,
      "comments": 3,
      "post_id": "t3_1n3ague",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "southbysoutheast94",
      "author_id": "t2_x0gh94v",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-29T15:26:36.160000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n3ague/creating_an_df_of_events_in_one_df_that_happened/",
      "content_preview": "Hey yâ€™all, Iâ€™m working a in a large database. I have two data frames. One with events and their date (we can call date_1) that I am primarily concerned about. The second is a large DF with other events and their dates (date_2). I am interested in creating a third DF of the events in DF2 that happened within 7 days of DF1â€™s events. Both DFs have person IDs and DF1 is the primary analytic file, Iâ€™m building. I tried a fuzzy join but from a memory standpoint this isnâ€™t feasible. I know thereâ€™s data.table approaches (or think there may be), but primarily learned R with base R + tidyverse so am less certain about that. Iâ€™ve chatted with the LLMs, would prefer to not just vibe code my way out. I am a late in life coder as my primary work is in medicine, so Iâ€™m learning as I go. Any tips?",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_7.png"
    },
    {
      "title": "Help with tidying data (updated)",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mdvg36/help_with_tidying_data_updated/",
      "score": 14,
      "comments": 8,
      "post_id": "t3_1mdvg36",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "RepresentativeTwo852",
      "author_id": "t2_aixeoh3t",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-31T07:49:19.884000+0000",
      "content_href": "https://i.redd.it/2pncvnmd06gf1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://preview.redd.it/help-with-tidying-data-updated-v0-2pncvnmd06gf1.jpeg?width=640&crop=smart&auto=webp&s=1b5fbcf3d093f864935c93d7e812474db0f6e96d"
    },
    {
      "title": "ggplot2() using short lines (and line types) to distinguish points",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n2lq9k/ggplot2_using_short_lines_and_line_types_to/",
      "score": 1,
      "comments": 5,
      "post_id": "t3_1n2lq9k",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "fasta_guy88",
      "author_id": "t2_2cpe6gvx",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-28T19:27:14.255000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n2lq9k/ggplot2_using_short_lines_and_line_types_to/",
      "content_preview": "Would like to plot 5 y-values for 20 categories, where I am using combinations of colors and symbols to distinguish the 20 categories in other plots.  So I am considering drawing short lines through the 20 color/symbol combinations, and using different line types (dotted, short-dashed, etc) to distinguish the 5 values. Is there a geom_??? that would allow me to draw a short line through a symbol that has been placed by its y-value and category?",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_5.png"
    },
    {
      "title": "[Q] Linear Regression & P-values (of regressors)",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mdgwfy/q_linear_regression_pvalues_of_regressors/",
      "score": 5,
      "comments": 3,
      "post_id": "t3_1mdgwfy",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Good-Breakfast-5585",
      "author_id": "t2_56lq6bktp",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-30T20:03:16.622000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mdgwfy/q_linear_regression_pvalues_of_regressors/",
      "content_preview": "Is it possible for a small sample size to have a large p-value? For example, say I'm collecting data on conductivity and chloride (Cl-) concentrations (both in the field and in the lab) and making a linear regression model to find if there is correlation (model: Cl = Î²1EC + u). Let's say that the actual relationship between Cl- and conductivity is a prefect correlation. When the sample size is small, I would imagine that the data in the field will a much larger p-value, as though the 2 are actually perfectly correlated, the residuals from field data will be a lot larger (due to omitted variables*), so the p-value of the coefficient will be a lot smaller.  However, as the sample size increases, the difference in residual coefficient from the lab model and the field model should decrease, I think. Is my understanding correct? If not, what have I misunderstood? Also, the smaller the p-value, the smaller the residuals, so the smaller the R 2 value, right? * Omitted variables could (from what I understand) lead to omitted variable bias (so the coefficients will be inaccurate). But (to my understanding), that is a slightly different topic.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "\"collapse\" in r",
      "permalink": "https://www.reddit.com/r/rstats/comments/1md58ei/collapse_in_r/",
      "score": 8,
      "comments": 28,
      "post_id": "t3_1md58ei",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "m0grady",
      "author_id": "t2_5p4j8",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-30T12:26:49.398000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1md58ei/collapse_in_r/",
      "content_preview": "stata user here: is there an equivalent to the collapse command in r? i have budget data by line item and department is a categorical variable. i want to sum at the department level.",
      "flair": [],
      "thumbnail_url": "https://styles.redditmedia.com/t5_1zpnj4/styles/profileIcon_t1wbyrfn8ak81.jpg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=fe254b938dce7cccae319d7d4d2edd49ef3dd68a"
    },
    {
      "title": "Shiny app to merge PDF files with page removal options",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n02y6u/shiny_app_to_merge_pdf_files_with_page_removal/",
      "score": 32,
      "comments": 8,
      "post_id": "t3_1n02y6u",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "pmxthrowaway",
      "author_id": "t2_tk5mpow",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-25T21:16:17.518000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n02y6u/shiny_app_to_merge_pdf_files_with_page_removal/",
      "content_preview": "Hi r/rstats , Just want to give back to the community on something I've worked on. I always get frustrated when I have the occasional need to merge PDF files and/or remove or rotate certain pages. Like most others, our corporate-default Acrobat Reader does not have these built-in features (why?), and we cannot use external websites to handle any sensitive info. Collectively, the world must've wasted many, many hours on this issue trying to find an acceptable workaround (e.g. finding a colleague that has the professional Adobe Acrobat, or wait for IT to install it on their own laptop). It's 2025 and no one else should suffer any more. So I've created an app called PDF Combiner that does exactly that. It is fast, free, and secure . Anyone with access to R can load this up locally in less than a minute, and no installation is required (other than a few common packages). Until Adobe decides to step up their game, this does the job. ðŸŒ Online demo ðŸ’» GitHub",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "How do to this kind of plot",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mbzqnq/how_do_to_this_kind_of_plot/",
      "score": 259,
      "comments": 45,
      "post_id": "t3_1mbzqnq",
      "post_type": "image",
      "domain": "i.redd.it",
      "author": "International_Mud141",
      "author_id": "t2_cpjdc0d0",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-29T02:28:29.928000+0000",
      "content_href": "https://i.redd.it/9eixvpib5qff1.jpeg",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "How to build a thriving R community: Lessons from Salt Lake City",
      "permalink": "https://www.reddit.com/r/rstats/comments/1mcen92/how_to_build_a_thriving_r_community_lessons_from/",
      "score": 22,
      "comments": 0,
      "post_id": "t3_1mcen92",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "jcasman",
      "author_id": "t2_34r89",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-29T15:34:29.569000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1mcen92/how_to_build_a_thriving_r_community_lessons_from/",
      "content_preview": "Julia Silge shares insights on growing an inclusive and technically rich R user group in Salt Lake City. From solo consultants to PhDs, the group brings together a wide range of backgrounds with a focus on community, consistency, and connection to the broader #rstats ecosystem. If you're running a local meetupâ€”or thinking about starting oneâ€”this post is worth a read. ðŸ”— https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/ Whatâ€™s worked (or not worked) in your local R/data science community? Would love to hear other experiences.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Rcpp Organization Logo",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n1pzks/rcpp_organization_logo/",
      "score": 4,
      "comments": 2,
      "post_id": "t3_1n1pzks",
      "post_type": "multi_media",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-27T19:04:12.337000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n1pzks/rcpp_organization_logo/",
      "content_preview": "The logo for the Rcpp GitHub organization features a clock pointing to 11. What does it mean? The C++11 standard, the package being created in 2011, or the package existing for 11 years, etc? https://github.com/RcppCore",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Rcpp is Highly Underrated",
      "permalink": "https://www.reddit.com/r/rstats/comments/1maxjxt/rcpp_is_highly_underrated/",
      "score": 68,
      "comments": 27,
      "post_id": "t3_1maxjxt",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-27T21:04:58.188000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1maxjxt/rcpp_is_highly_underrated/",
      "content_preview": "Whenever I need a faster function, I can write it in C++ and call it from R via Rcpp. To my best knowledge, Python still does not have something that can compile C++ codes on the fly as seamless as Rcpp. The closest one is cppyy, but it is not as good and lacks adoption.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "I'm making some ggplot tutorials for beginners",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m9ri2g/im_making_some_ggplot_tutorials_for_beginners/",
      "score": 107,
      "comments": 9,
      "post_id": "t3_1m9ri2g",
      "post_type": "link",
      "domain": "youtu.be",
      "author": "Amber32K",
      "author_id": "t2_1c2s1jfxvk",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-26T11:56:39.698000+0000",
      "content_href": "https://youtu.be/vxByOAN84s4?si=pgH0Hv90Ep4KrKLJ",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "I often see people in this subreddit using three backticks for code blocks or wrong format for tables on reddit, presuming it's identical to Markdown. So I made a Markdown to reddit converter!",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m9xl9u/i_often_see_people_in_this_subreddit_using_three/",
      "score": 12,
      "comments": 1,
      "post_id": "t3_1m9xl9u",
      "post_type": "link",
      "domain": "markdown-to-reddit.pages.dev",
      "author": "BIOffense",
      "author_id": "t2_10m8zcm27t",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-26T16:26:34.718000+0000",
      "content_href": "https://markdown-to-reddit.pages.dev",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Switch from RStudio to Positron",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m92ne6/switch_from_rstudio_to_positron/",
      "score": 49,
      "comments": 23,
      "post_id": "t3_1m92ne6",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "jaimers215",
      "author_id": "t2_81qbglhe",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-25T15:45:08.401000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1m92ne6/switch_from_rstudio_to_positron/",
      "content_preview": "Howdy friends, I am trying to switch from RStudio to the Positron IDE. I am fairly well stuck on stupid with this transition. Do any of you have any good video recommendations to orient me to Positron better? Thank you!",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "IIT JAM and GATE preparation",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m90h4a/iit_jam_and_gate_preparation/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1m90h4a",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "sleekcinch",
      "author_id": "t2_fksi819vl",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-25T14:21:47.253000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1m90h4a/iit_jam_and_gate_preparation/",
      "content_preview": "I'm currently in my third year of B.Sc. (Hons.) in Statistics and I'm interested in pursuing an M.Sc. in Data Science from an IIT. I'm planning to appear for IIT JAM and GATE exams, but I'm unsure how to start my preparation. With all the changes under NEP, Iâ€™m a bit confusedâ€”will my honors degree still make me eligible for a masterâ€™s at IIT? Can someone guide me on how to begin, what resources to use, and how much time to dedicate? My qualifications: B.Sc. Statistics (Hons.), currently in 3rd year.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Replicability of Random Forests",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n2mio9/replicability_of_random_forests/",
      "score": 4,
      "comments": 2,
      "post_id": "t3_1n2mio9",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "BOBOLIU",
      "author_id": "t2_23yqc963",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-28T19:57:40.389000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n2mio9/replicability_of_random_forests/",
      "content_preview": "I use the R package ranger for random forests modeling, but I am unsure how to maintain replicability. I can use the base function set.seed(), but the function ranger() also has an argument seed. The function importance_pvalues() also needs to set seed when the Altmann method is used. Any suggestions?",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "R-studio/Python with a BA",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n0bn5o/rstudiopython_with_a_ba/",
      "score": 3,
      "comments": 10,
      "post_id": "t3_1n0bn5o",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Crafty-Fisherman-241",
      "author_id": "t2_lntm8sdnv",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-26T03:45:11.776000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n0bn5o/rstudiopython_with_a_ba/",
      "content_preview": "I am a senior majoring in Political Science (BA) at a DC school. My school is somewhat unique in the land of theoretical-based Political Science degrees and I have taken 6 econ classes as well as a TA position with a micro class (earning a minor), a introductory statistics course, as well as having learned SPSS through a quantitative-based research class. However, I feel this is still not enough to justify a valuable, competitive skill set as SPSS is not widely used anymore it seems and other than that, what can I say... I can read and analyze well? So this is my dilemma and I find myself wanting to add another semester (I was supposed to graduate early this December so this wont really delay my plans, just my wallet) and take both an R-studio class and Python class. I would also add a data analytics class that develops a research paper with multiple coding programs. Is it a good idea to pursue a more statistical route? Any advice about this area helps. I loved my research class and messing with datasets and SPSS even tho it's a piece of shit on my computer. I want to be competitive for graduate schools and the job market and my career advisors have told me that polisci and policy analysis is going down a more quantitative route.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Is there a way to order data according to two factors on the x-axis?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m8va47/is_there_a_way_to_order_data_according_to_two/",
      "score": 4,
      "comments": 5,
      "post_id": "t3_1m8va47",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Frosty_Lawfulness_24",
      "author_id": "t2_9hh2wxtl",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-25T10:08:50.453000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1m8va47/is_there_a_way_to_order_data_according_to_two/",
      "content_preview": "Hi! Is there a way to order data according to two factors on the x-axis? I have a dataset of temperature data over several years. I want to plot the means per season for each year in a geom_point(). I have Year and Season as two factors, and mean Temperature as my dependent variable. Is there a way to plot this so i have the seasons in order over the years (so 2005: spring, summer, autumn, winter; 2006: spring, summer, autumn, winter; etc)? I have tried making a combined Year_Season factor, but then it just keeps ordering itself by season, so i get all the springs of every year first, etc...",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Does pseudo-R2 represent an appropriate measure of goodness-of-fit for Conway-Maxwell Possion?",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n0qbr5/does_pseudor2_represent_an_appropriate_measure_of/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1n0qbr5",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Pseudachristopher",
      "author_id": "t2_1m4z7hb5o8",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-26T16:20:43.435000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n0qbr5/does_pseudor2_represent_an_appropriate_measure_of/",
      "content_preview": "Good morning, I have a question regarding Conway-Maxwell Poisson and pseduo-R2. In R, I have fitted a model using glmmTMB as such: richness_glmer_Full <- glmmTMB(richness ~ vl100m_cs + roads100m_cs + (1 | neighbourhood/site), data = df_Bird, family = \"compois\", na.action = \"na.fail\") I elected to use a COMPOIS due to evidence of underdispersion. COMPOIS mitigates the issue of underdispersion well, but my concern lies in the subsequent calculation of pseudo-R2: r.squaredGLMM(richness_glmer_Full) R2m R2c [1,] 0.06240816 0.08230917 I'm skeptical that the model has such low explanatory power (models fit with different error structures show much higher marginal R2). Am I correct in assuming that using a COMPOIS error structure leads to these low pseudo-R2 values (i.e., something related to the computation of pseudo-R2 with COMPOIS leads to deflated values). Any insight for this humble ecologist would be greatly appreciated. Thank you in advance.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "R course certification",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n09fbu/r_course_certification/",
      "score": 2,
      "comments": 11,
      "post_id": "t3_1n09fbu",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "New_Dragonfruit_350",
      "author_id": "t2_rb8wbt3s",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-26T01:55:04.578000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n09fbu/r_course_certification/",
      "content_preview": "Hello all, I am completely new to R, with absolutely 0 experience in it. I wanted to complete a certification or just be in the process of one for upcoming masters applications for biotech. I wanted an actual certification to show credentials as opposed to learning it myself through books. I saw a few on coursera but I wanted to know if anyone had any recommendations? Any help would be MUCH appreciated",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Recreating a New York Times Chart in R  | Line-by-line Coding Tutorial",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m85ghv/recreating_a_new_york_times_chart_in_r_linebyline/",
      "score": 35,
      "comments": 0,
      "post_id": "t3_1m85ghv",
      "post_type": "link",
      "domain": "youtu.be",
      "author": "Pecners",
      "author_id": "t2_35337pgu",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-24T14:10:42.540000+0000",
      "content_href": "https://youtu.be/HDCJIkY2ihI",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "Show me beautiful R code",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m6bzng/show_me_beautiful_r_code/",
      "score": 92,
      "comments": 64,
      "post_id": "t3_1m6bzng",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "Top_Lime1820",
      "author_id": "t2_6x5m4wqy",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-22T11:50:57.391000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1m6bzng/show_me_beautiful_r_code/",
      "content_preview": "I really love seeing beautiful code (as in aesthetically pleasing). I don't think there is just one way of making code beautiful though. With Python I like one line does one thing code even if you end up with lots of intermediate variables. With (Frontend) Javascript (React), I love the way they define functions within functions and use lambdas literally everywhere. I'd like to see examples of R code that you think is beautiful to look at. I know that R is extremely flexible, and that base, data.table and tidyverse are basically different dialects of R. But I love the diversity and I want to see whatever so long as it looks beautiful. Pipes, brackets, even right-assign arrows... throw 'em at me.",
      "flair": [],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "I'm new and I need some help step-by-step if possible",
      "permalink": "https://www.reddit.com/r/rstats/comments/1n2k575/im_new_and_i_need_some_help_stepbystep_if_possible/",
      "score": 2,
      "comments": 7,
      "post_id": "t3_1n2k575",
      "post_type": "text",
      "domain": "self.rstats",
      "author": "unceasingfish",
      "author_id": "t2_87krvp1e",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-08-28T18:26:49.247000+0000",
      "content_href": "https://www.reddit.com/r/rstats/comments/1n2k575/im_new_and_i_need_some_help_stepbystep_if_possible/",
      "content_preview": "Hello all, I posted a few days ago before I left to do field work. I am now going back to my data analysis for the project that I posted about. I do not think that the codes are working as they should, leading to errors. My coworker created this code. I wanted someone to coach me step-by-step because my coworker is still out on vacation. As of right now this is my code for the uploading of packages, data, directory, and cleaning data. This is the beginning of the code. ### Load Packages ###\n\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\n\n### Directory to File Location ###\ndataAll <- read_csv(\"T:/HSC/Marsh_Fiddler/Analysis/All_Blocks_All_Data.csv\")\ndataSites <- read_csv(\"T:/HSC/Marsh_Fiddler/Analysis/tbl_MarshSurvey.csv\")\ndataBlocks <- read_csv(\"T:/HSC/Marsh_Fiddler/Analysis/tbl_BlocksAnna.csv\")\n\nindata <- read_excel(\"T:/HSC/Marsh_Fiddler/Analysis/All_Blocks_All_Data.xlsx\", sheet = \"Bay\", col_types = c(\"date\",\"text\", \"text\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\n\nhead(indata)\n\nstr(indata)\n\n#---- Clean and prep data ----\n\n# unfortunately, not all the CSV files come in with the same variables in the same format\n# make any adjustments and add any additional columns that you need/want\nstr(\"dataBlocks\")\ndataBlocks2 <- dataBlocks %>%\n  mutate(SurveyID = as.factor(SurveyID),\n         Year = as.factor(year(SurveyDate)),\n         Month = as.factor(month(SurveyDate))) #%>%\n#select(!c(BlockID))\n\ndataSites2 <- dataSites %>%\n  mutate(SurveyDate = mdy(SurveyDate),\n         Location = as.factor(Location),\n         TideCode = as.factor(TideCode),\n         Year = as.factor(year(SurveyDate)),\n         Month = as.factor(month(SurveyDate)),\n         State =  \"DE\") %>%\n  select(!c(Crew))\n\nstr(dataSites2) \n\n# select(!c(SurveyID)) The first str() command appears to go through. However, the code below goes to error. dataBlocks2 <- dataBlocks %>%\n  mutate(SurveyID = as.factor(SurveyID),\n         Year = as.factor(year(SurveyDate)),\n         Month = as.factor(month(SurveyDate))) The error for the code is Error in `mutate()`:\nâ„¹ In argument: `Year = as.factor(year(SurveyDate))`.\nCaused by error in `as.POSIXlt.character()`:\n! character string is not in a standard unambiguous format\nRun `` to see where the error occurred.rlang::last_trace() I believe that dataBlocks2 was supposed to be created by that command, but it isn't and when I run the next str() command it says that dataBlocks2 cannot be found. I also assume that this is happening with dataSites as well.",
      "flair": [],
      "thumbnail_url": ""
    },
    {
      "title": "If you use R, you need to know R Markdown â€” itâ€™s a must-have tool",
      "permalink": "https://www.reddit.com/r/rstats/comments/1m5u33k/if_you_use_r_you_need_to_know_r_markdown_its_a/",
      "score": 80,
      "comments": 40,
      "post_id": "t3_1m5u33k",
      "post_type": "link",
      "domain": "youtu.be",
      "author": "OnlyDemor",
      "author_id": "t2_7d8gnugw",
      "subreddit_id": "t5_2r8n0",
      "subreddit": "r/rstats",
      "created_ts": "2025-07-21T20:30:29.679000+0000",
      "content_href": "https://youtu.be/cWbG26gKOpM",
      "content_preview": "",
      "flair": [],
      "thumbnail_url": ""
    }
  ],
  "scraped_at": "2025-09-02T11:13:52.159625"
}