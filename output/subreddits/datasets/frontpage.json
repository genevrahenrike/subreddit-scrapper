{
  "subreddit": "datasets",
  "url": "https://www.reddit.com/r/datasets",
  "meta": {
    "title": "Datasets"
  },
  "posts": [
    {
      "title": "I started learning Data analysis almost 60-70% completed. I'm confused",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n3ue6u/i_started_learning_data_analysis_almost_6070/",
      "score": 0,
      "comments": 3,
      "post_id": "t3_1n3ue6u",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Old-Investment-6969",
      "author_id": "t2_1j71x5tdh0",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-30T06:17:50.652000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n3ue6u/i_started_learning_data_analysis_almost_6070/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Website-Crawler: Extract data from websites in LLM ready JSON or CSV format. Crawl or Scrape entire website with Website Crawler",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n19at9/websitecrawler_extract_data_from_websites_in_llm/",
      "score": 10,
      "comments": 1,
      "post_id": "t3_1n19at9",
      "post_type": "crosspost",
      "domain": "github.com",
      "author": "Fluid-Engineering769",
      "author_id": "t2_1ltl2481o8",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-27T06:10:31.444000+0000",
      "content_href": "/r/ollama/comments/1n189ws/websitecrawler_extract_data_from_websites_in_llm/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Istanbul open data portal. There's Street cats but I can't find them",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n4t376/istanbul_open_data_portal_theres_street_cats_but/",
      "score": 2,
      "comments": 1,
      "post_id": "t3_1n4t376",
      "post_type": "link",
      "domain": "data.ibb.gov.tr",
      "author": "cavedave",
      "author_id": "t2_1vrx",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-31T12:11:56.407000+0000",
      "content_href": "https://data.ibb.gov.tr/en/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "A Massive Amount of Data about Every Number One Hit Song in History",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mornvt/a_massive_amount_of_data_about_every_number_one/",
      "score": 17,
      "comments": 7,
      "post_id": "t3_1mornvt",
      "post_type": "link",
      "domain": "docs.google.com",
      "author": "noisymortimer",
      "author_id": "t2_vtqhznb5",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-13T01:49:28.078000+0000",
      "content_href": "https://docs.google.com/spreadsheets/d/1j1AUgtMnjpFTz54UdXgCKZ1i4bNxFjf01ImJ-BqBEt0/edit?gid=1974823090#gid=1974823090",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Patient Dataset for patient health detoriation prediction model",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n4sq1x/patient_dataset_for_patient_health_detoriation/",
      "score": 2,
      "comments": 2,
      "post_id": "t3_1n4sq1x",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Ok-Blacksmith3087",
      "author_id": "t2_rcm9zx4jk",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-31T11:52:54.996000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n4sq1x/patient_dataset_for_patient_health_detoriation/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": "https://styles.redditmedia.com/t5_ai0qtk/styles/profileIcon_dmxha7sinwlf1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=4413365c364749c18739168a270ac0d7cd99b360"
    },
    {
      "title": "A clean, combined dataset of all Academy Award (Oscar) winners from 1928-Present.",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n2nba5/a_clean_combined_dataset_of_all_academy_award/",
      "score": 8,
      "comments": 1,
      "post_id": "t3_1n2nba5",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Bootes-sphere",
      "author_id": "t2_a0h6keim",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-28T20:28:09.444000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n2nba5/a_clean_combined_dataset_of_all_academy_award/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "#Want help finding an Indian Specific Vechile Dataset",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n3g6r7/want_help_finding_an_indian_specific_vechile/",
      "score": 2,
      "comments": 3,
      "post_id": "t3_1n3g6r7",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Responsible-Wheel854",
      "author_id": "t2_lkh5em8k",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-29T19:03:45.020000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n3g6r7/want_help_finding_an_indian_specific_vechile/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "QUEENS: Python ETL + API for making energy datasets machine readable",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n1bc0q/queens_python_etl_api_for_making_energy_datasets/",
      "score": 1,
      "comments": 1,
      "post_id": "t3_1n1bc0q",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "KaleidoscopeNo6551",
      "author_id": "t2_hzowt7kf4",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-27T08:22:05.334000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n1bc0q/queens_python_etl_api_for_making_energy_datasets/",
      "content_preview": "",
      "flair": [
        "API"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Dataset Explorer – Tool to search any public datasets (Free Forever)",
      "permalink": "https://www.reddit.com/r/datasets/comments/1moena8/dataset_explorer_tool_to_search_any_public/",
      "score": 15,
      "comments": 1,
      "post_id": "t3_1moena8",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "matkley12",
      "author_id": "t2_8zs7vrkq",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-12T17:12:20.554000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1moena8/dataset_explorer_tool_to_search_any_public/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Best Datasets for US 10DLC Phone number lookups?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n33vbn/best_datasets_for_us_10dlc_phone_number_lookups/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1n33vbn",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "MiloCOOH",
      "author_id": "t2_abt27jv",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-29T10:35:40.655000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n33vbn/best_datasets_for_us_10dlc_phone_number_lookups/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "Stuck on extracting structured data from charts/graphs — OCR not working well",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n0glo7/stuck_on_extracting_structured_data_from/",
      "score": 3,
      "comments": 6,
      "post_id": "t3_1n0glo7",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Fit-Soup9023",
      "author_id": "t2_zv1eatn3h",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T08:51:07.168000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n0glo7/stuck_on_extracting_structured_data_from/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "I need help with scraping Redfin URLS",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n328lr/i_need_help_with_scraping_redfin_urls/",
      "score": 1,
      "comments": 2,
      "post_id": "t3_1n328lr",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Interesting_Rent6155",
      "author_id": "t2_1fq4nhdyru",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-29T08:56:43.264000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n328lr/i_need_help_with_scraping_redfin_urls/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "How are you ingesting data into your database?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n11me5/how_are_you_ingesting_data_into_your_database/",
      "score": 3,
      "comments": 1,
      "post_id": "t3_1n11me5",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "fruitstanddev",
      "author_id": "t2_1g2a6q3wfe",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T23:40:12.464000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n11me5/how_are_you_ingesting_data_into_your_database/",
      "content_preview": "",
      "flair": [
        "code"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "Seeking NCAA Division II Baseball Data API for Personal Project",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n2f1xk/seeking_ncaa_division_ii_baseball_data_api_for/",
      "score": 1,
      "comments": 1,
      "post_id": "t3_1n2f1xk",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Sharp_Network7139",
      "author_id": "t2_cgicpjtbe",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-28T15:16:08.102000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n2f1xk/seeking_ncaa_division_ii_baseball_data_api_for/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_2.png"
    },
    {
      "title": "Open sourced a CLI that turns PDFs and docs into fine tuning datasets now with multi file support",
      "permalink": "https://www.reddit.com/r/datasets/comments/1muin9k/open_sourced_a_cli_that_turns_pdfs_and_docs_into/",
      "score": 13,
      "comments": 1,
      "post_id": "t3_1muin9k",
      "post_type": "multi_media",
      "domain": "self.datasets",
      "author": "Interesting-Area6418",
      "author_id": "t2_r9001m4az",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-19T13:36:13.157000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1muin9k/open_sourced_a_cli_that_turns_pdfs_and_docs_into/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Need massive collections of schemas for AI training - any bulk sources?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n2c5xb/need_massive_collections_of_schemas_for_ai/",
      "score": 0,
      "comments": 3,
      "post_id": "t3_1n2c5xb",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Fragrant-Dog-3706",
      "author_id": "t2_1j0ajy7rie",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-28T13:25:21.474000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n2c5xb/need_massive_collections_of_schemas_for_ai/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Real Estate Data (Rents by bedroom, home prices, etc) broken down by Zip Code",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mw1024/real_estate_data_rents_by_bedroom_home_prices_etc/",
      "score": 9,
      "comments": 2,
      "post_id": "t3_1mw1024",
      "post_type": "link",
      "domain": "prop-metrics.com",
      "author": "prop-metrics",
      "author_id": "t2_1d1m49gjrq",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-21T04:16:07.018000+0000",
      "content_href": "https://www.prop-metrics.com/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "Looking for a dataset of domains + social media ids",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n0zyg1/looking_for_a_dataset_of_domains_social_media_ids/",
      "score": 2,
      "comments": 5,
      "post_id": "t3_1n0zyg1",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "ZeroToHeroInvest",
      "author_id": "t2_fkkjbofz",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T22:28:23.334000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n0zyg1/looking_for_a_dataset_of_domains_social_media_ids/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "In need of mental disorder dataset of children's.",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n0em8s/in_need_of_mental_disorder_dataset_of_childrens/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1n0em8s",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Hefty_Antelope7469",
      "author_id": "t2_bw5pcr8b",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T06:39:24.075000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n0em8s/in_need_of_mental_disorder_dataset_of_childrens/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "API to find the right Amazon categories for a product from title and description. Feedback appreciated",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n0eomh/api_to_find_the_right_amazon_categories_for_a/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1n0eomh",
      "post_type": "multi_media",
      "domain": "self.datasets",
      "author": "textclf",
      "author_id": "t2_1t4ryze8cs",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T06:43:52.521000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n0eomh/api_to_find_the_right_amazon_categories_for_a/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_4.png"
    },
    {
      "title": "Hey I need to build a database for pc components",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n13ugc/hey_i_need_to_build_a_database_for_pc_components/",
      "score": 0,
      "comments": 1,
      "post_id": "t3_1n13ugc",
      "post_type": "crosspost",
      "domain": "reddit.com",
      "author": "Longjumping-Monk-411",
      "author_id": "t2_1qosbk3owc",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-27T01:22:31.298000+0000",
      "content_href": "/r/Database/comments/1n13r9y/hey_i_need_to_build_a_database/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Looking for mimic 3 dataset for my upcoming minor project",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n25h9s/looking_for_mimic_3_dataset_for_my_upcoming_minor/",
      "score": 1,
      "comments": 1,
      "post_id": "t3_1n25h9s",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "JARVIS__73",
      "author_id": "t2_spyf8tav5",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-28T07:09:15.781000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n25h9s/looking_for_mimic_3_dataset_for_my_upcoming_minor/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Looking for a Dataset on Competitive Pokemon battles(mostly VGC)",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n20upf/looking_for_a_dataset_on_competitive_pokemon/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1n20upf",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Malice15",
      "author_id": "t2_cb34s6gbk",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-28T02:45:47.411000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n20upf/looking_for_a_dataset_on_competitive_pokemon/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "marketplace to sell nature video footage for LLM training",
      "permalink": "https://www.reddit.com/r/datasets/comments/1myk4g3/marketplace_to_sell_nature_video_footage_for_llm/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1myk4g3",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "amazonbe",
      "author_id": "t2_s3w112lr",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-24T02:33:29.747000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1myk4g3/marketplace_to_sell_nature_video_footage_for_llm/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Labeling 10k sentences manually vs letting the model pick the useful ones 😂 (uni project on smarter text labeling)",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mvgltd/labeling_10k_sentences_manually_vs_letting_the/",
      "score": 8,
      "comments": 0,
      "post_id": "t3_1mvgltd",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "vihanga2001",
      "author_id": "t2_5z701ac0e",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-20T14:38:00.781000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mvgltd/labeling_10k_sentences_manually_vs_letting_the/",
      "content_preview": "",
      "flair": [
        "discussion"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "Where to to purchase licensed videos for AI training?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1n0pbm6/where_to_to_purchase_licensed_videos_for_ai/",
      "score": 1,
      "comments": 2,
      "post_id": "t3_1n0pbm6",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Mariolotus",
      "author_id": "t2_ar8muxyu",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-26T15:42:11.650000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1n0pbm6/where_to_to_purchase_licensed_videos_for_ai/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_6.png"
    },
    {
      "title": "What’s the most comprehensive medical dataset you’ve used that includes EHRs, physician dictation, and imaging (CT, MRI, X-ray)? How well did it cover diverse patient demographics and geographic regions?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mzuhlq/whats_the_most_comprehensive_medical_dataset/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1mzuhlq",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Selmakiley",
      "author_id": "t2_g4crd9x7",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-25T16:00:52.127000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mzuhlq/whats_the_most_comprehensive_medical_dataset/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://styles.redditmedia.com/t5_59v5pk/styles/profileIcon_imadl2lry5x71.jpeg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=8dc3c82b2f7114de7b8ee1a46f7f4f384f10f233"
    },
    {
      "title": "Looking for research partners who need synthetic tabular datasets",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mzknyy/looking_for_research_partners_who_need_synthetic/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1mzknyy",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Adrian2vp",
      "author_id": "t2_lqqq1hr1",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-25T08:12:24.769000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mzknyy/looking_for_research_partners_who_need_synthetic/",
      "content_preview": "",
      "flair": [
        "discussion"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_5.png"
    },
    {
      "title": "What to do with a dataset of 1.1 Billion RSS feeds?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mrafik/what_to_do_with_a_dataset_of_11_billion_rss_feeds/",
      "score": 8,
      "comments": 16,
      "post_id": "t3_1mrafik",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Horror-Tower2571",
      "author_id": "t2_12uawr2y4s",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-15T21:08:27.024000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mrafik/what_to_do_with_a_dataset_of_11_billion_rss_feeds/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Harvard University lays off fly database team",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mqe53o/harvard_university_lays_off_fly_database_team/",
      "score": 6,
      "comments": 3,
      "post_id": "t3_1mqe53o",
      "post_type": "link",
      "domain": "thetransmitter.org",
      "author": "cavedave",
      "author_id": "t2_1vrx",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-14T21:39:01.073000+0000",
      "content_href": "https://www.thetransmitter.org/community/harvard-university-lays-off-fly-database-team/",
      "content_preview": "",
      "flair": [
        "discussion"
      ],
      "thumbnail_url": "https://external-preview.redd.it/1SeRpkWJkKwITGqfGP8UYhiORy6Vuwr8VvikY82DD0M.png?width=140&height=73&crop=140:73,smart&auto=webp&s=769532690f16d5d5c3064f2352a6c10dd82c529f"
    },
    {
      "title": "Update on an earlier post about 300 million RSS feeds",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mwnv3j/update_on_an_earlier_post_about_300_million_rss/",
      "score": 6,
      "comments": 6,
      "post_id": "t3_1mwnv3j",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Horror-Tower2571",
      "author_id": "t2_12uawr2y4s",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-21T21:29:45.295000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mwnv3j/update_on_an_earlier_post_about_300_million_rss/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "[Request] Looking for datasets of 2D point sequences for shape approximation",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mz2m24/request_looking_for_datasets_of_2d_point/",
      "score": 3,
      "comments": 1,
      "post_id": "t3_1mz2m24",
      "post_type": "multi_media",
      "domain": "self.datasets",
      "author": "zimmer550king",
      "author_id": "t2_11zopg",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-24T17:59:28.432000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mz2m24/request_looking_for_datasets_of_2d_point/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Haether. Coding data set api, made by an ai model",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mytydo/haether_coding_data_set_api_made_by_an_ai_model/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1mytydo",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "CurtissYT",
      "author_id": "t2_tajxekc3u",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-24T12:12:07.677000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mytydo/haether_coding_data_set_api_made_by_an_ai_model/",
      "content_preview": "",
      "flair": [
        "API"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Looking for time-series waveform data with repeatable peaks and troughs (systole/diastole–like) for labeling project",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mydg0x/looking_for_timeseries_waveform_data_with/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1mydg0x",
      "post_type": "multi_media",
      "domain": "self.datasets",
      "author": "xpmoonlight1",
      "author_id": "t2_118xn95i5p",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-23T21:22:28.057000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mydg0x/looking_for_timeseries_waveform_data_with/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Hi guys, I just opened up my SEC data platform API + Docs, feel free to try it out",
      "permalink": "https://www.reddit.com/r/datasets/comments/1my5777/hi_guys_i_just_opened_up_my_sec_data_platform_api/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1my5777",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "ccnomas",
      "author_id": "t2_1kunweljpk",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-23T15:59:12.465000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1my5777/hi_guys_i_just_opened_up_my_sec_data_platform_api/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_0.png"
    },
    {
      "title": "Kijiji and Facebook Automatic Poster Script",
      "permalink": "https://www.reddit.com/r/datasets/comments/1my0k4s/kijiji_and_facebook_automatic_poster_script/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1my0k4s",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "YoghurtFinal1845",
      "author_id": "t2_il8jz3gx",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-23T12:47:47.958000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1my0k4s/kijiji_and_facebook_automatic_poster_script/",
      "content_preview": "",
      "flair": [
        "code"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Which voting poll tool offers the most customization options?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mw4y30/which_voting_poll_tool_offers_the_most/",
      "score": 2,
      "comments": 1,
      "post_id": "t3_1mw4y30",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Saratan0326",
      "author_id": "t2_vj4sezck0",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-21T08:10:08.040000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mw4y30/which_voting_poll_tool_offers_the_most/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "I need to pull data on all of Count Von Count's tweets",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mxivw8/i_need_to_pull_data_on_all_of_count_von_counts/",
      "score": 1,
      "comments": 2,
      "post_id": "t3_1mxivw8",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "ConsistentAmount4",
      "author_id": "t2_11ynpja",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-22T21:23:23.717000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mxivw8/i_need_to_pull_data_on_all_of_count_von_counts/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Where do you find real messy datasets for portfolio projects that aren't Titanic or Iris?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mptl8o/where_do_you_find_real_messy_datasets_for/",
      "score": 5,
      "comments": 5,
      "post_id": "t3_1mptl8o",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Various_Candidate325",
      "author_id": "t2_1opfd7qzej",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-14T07:15:00.853000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mptl8o/where_do_you_find_real_messy_datasets_for/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Where to find dataset other than kaggle ?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mwgudg/where_to_find_dataset_other_than_kaggle/",
      "score": 0,
      "comments": 6,
      "post_id": "t3_1mwgudg",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "0909kyu",
      "author_id": "t2_en6rk99hm",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-21T17:05:20.026000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mwgudg/where_to_find_dataset_other_than_kaggle/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "Preserving Family Tree Data For Generations To Come",
      "permalink": "https://www.reddit.com/r/datasets/comments/1murs2d/preserving_family_tree_data_for_generations_to/",
      "score": 2,
      "comments": 0,
      "post_id": "t3_1murs2d",
      "post_type": "crosspost",
      "domain": "reddit.com",
      "author": "innomind",
      "author_id": "t2_13e8z9",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-19T19:05:51.398000+0000",
      "content_href": "/r/Genealogy/comments/1murcxt/preserving_family_tree_data_for_generations_to/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_5.png"
    },
    {
      "title": "Google maps scrapping for large dataset",
      "permalink": "https://www.reddit.com/r/datasets/comments/1muamaj/google_maps_scrapping_for_large_dataset/",
      "score": 2,
      "comments": 7,
      "post_id": "t3_1muamaj",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Existing_Pay8831",
      "author_id": "t2_j0hvwz4x",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-19T06:21:14.493000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1muamaj/google_maps_scrapping_for_large_dataset/",
      "content_preview": "",
      "flair": [
        "dataset"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Looking for dataset on \"ease of remembering numbers\"",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mtsl8o/looking_for_dataset_on_ease_of_remembering_numbers/",
      "score": 2,
      "comments": 2,
      "post_id": "t3_1mtsl8o",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "abel_maireg",
      "author_id": "t2_13s9alhzre",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-18T17:28:56.904000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mtsl8o/looking_for_dataset_on_ease_of_remembering_numbers/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "[D] The Stack Processed V2 - Curated 468GB Multi-Language Code Dataset (91.3% Syntax Valid, Perfectly Balanced)",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mtmsxx/d_the_stack_processed_v2_curated_468gb/",
      "score": 2,
      "comments": 1,
      "post_id": "t3_1mtmsxx",
      "post_type": "multi_media",
      "domain": "self.datasets",
      "author": "CodeStackDev",
      "author_id": "t2_1s56c0u2mx",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-18T13:57:48.964000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mtmsxx/d_the_stack_processed_v2_curated_468gb/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://styles.redditmedia.com/t5_erosdo/styles/profileIcon_w4uw7mkq4s8f1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=38c12eb003087624674cfca264c15773c1e5e320"
    },
    {
      "title": "[Synthetic] Multilingual Customer Support Chat Logs – English, Spanish, French (Free, Privacy-Safe, Created with MOSTLY AI)",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mzmh35/synthetic_multilingual_customer_support_chat_logs/",
      "score": 5,
      "comments": 1,
      "post_id": "t3_1mzmh35",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "ZealousidealCard4582",
      "author_id": "t2_1lztb7p30j",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-25T10:09:00.437000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mzmh35/synthetic_multilingual_customer_support_chat_logs/",
      "content_preview": "",
      "flair": [
        "mock dataset"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_3.png"
    },
    {
      "title": "Low quality football datasets for player detection models.",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mtuprv/low_quality_football_datasets_for_player/",
      "score": 1,
      "comments": 0,
      "post_id": "t3_1mtuprv",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "cantfindux",
      "author_id": "t2_d6xz7i80x",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-18T18:45:17.922000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mtuprv/low_quality_football_datasets_for_player/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "How do you collect and structure data for an AI after-sales (SAV) agent in banking/insurance?",
      "permalink": "https://www.reddit.com/r/datasets/comments/1msobmk/how_do_you_collect_and_structure_data_for_an_ai/",
      "score": 0,
      "comments": 2,
      "post_id": "t3_1msobmk",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "seriousdeadmen47",
      "author_id": "t2_v5ofkhl",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-17T11:21:27.940000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1msobmk/how_do_you_collect_and_structure_data_for_an_ai/",
      "content_preview": "",
      "flair": [
        "question"
      ],
      "thumbnail_url": ""
    },
    {
      "title": "[self-promotion] An easier way to access US Census ACS data (since QuickFacts is down).",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mt9ats/selfpromotion_an_easier_way_to_access_us_census/",
      "score": 0,
      "comments": 0,
      "post_id": "t3_1mt9ats",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Substantial-North137",
      "author_id": "t2_1lwku3xofe",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-18T02:00:53.273000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mt9ats/selfpromotion_an_easier_way_to_access_us_census/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://styles.redditmedia.com/t5_e6odo0/styles/profileIcon_ggxft4sy9oue1.png?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=94b070306add0007e95b2aca21d2deade871570b"
    },
    {
      "title": "Looking for high quality datasets of plastic litter on ground and water",
      "permalink": "https://www.reddit.com/r/datasets/comments/1mqyj60/looking_for_high_quality_datasets_of_plastic/",
      "score": 2,
      "comments": 4,
      "post_id": "t3_1mqyj60",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "CartographerOk858",
      "author_id": "t2_j3we34sp",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-15T13:54:32.139000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1mqyj60/looking_for_high_quality_datasets_of_plastic/",
      "content_preview": "",
      "flair": [
        "request"
      ],
      "thumbnail_url": "https://www.redditstatic.com/avatars/defaults/v2/avatar_default_1.png"
    },
    {
      "title": "Dataset de +120.000 productos con códigos de barras (EAN-13), descripciones normalizadas y formato CSV para retail, kioscos, supermercados y e-commerce en Argentina/LatAm",
      "permalink": "https://www.reddit.com/r/datasets/comments/1myhmlq/dataset_de_120000_productos_con_códigos_de_barras/",
      "score": 4,
      "comments": 1,
      "post_id": "t3_1myhmlq",
      "post_type": "text",
      "domain": "self.datasets",
      "author": "Tricky-Birthday-176",
      "author_id": "t2_aiu8kfrl",
      "subreddit_id": "t5_2r97t",
      "subreddit": "r/datasets",
      "created_ts": "2025-08-24T00:26:57.280000+0000",
      "content_href": "https://www.reddit.com/r/datasets/comments/1myhmlq/dataset_de_120000_productos_con_c%C3%B3digos_de_barras/",
      "content_preview": "",
      "flair": [
        "resource"
      ],
      "thumbnail_url": "https://styles.redditmedia.com/t5_40mcmf/styles/profileIcon_fdhopqxkx3af1.jpeg?width=64&height=64&frame=1&auto=webp&crop=64%3A64%2Csmart&s=8bd262cad967de453e9fd13179a47ddf2fc241cf"
    }
  ],
  "scraped_at": "2025-09-02T07:09:01.570738"
}